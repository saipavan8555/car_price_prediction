# -*- coding: utf-8 -*-
"""car_price_Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bZMduomLews_KAgh6yatptSvSvZMhJPv
"""

# importing the requried libraries

import numpy as np
import pandas as pd
import pandas as pd
import cv2
import matplotlib.pyplot as plt

from google.colab.patches import cv2_imshow

#connecting to drive
from google.colab import drive
drive.mount('/content/drive')

#function that load image in the given url
def read_images_using_url(url):
  import requests
  from PIL import Image
  from io import BytesIO

  response = requests.get(url)
  img = Image.open(BytesIO(response.content))
  img.show()

"""most of the times urls are not working for some urls its working for others not 
 its may be the problem with the libraries so we  use downloaded images to get output
"""



#working url
read_images_using_url(url = "https://cdn.pixabay.com/photo/2016/04/01/12/16/car-1300629_960_720.png")
#'https://cdn.pixabay.com/photo/2020/03/25/15/15/honda-4967605_960_720.jpg

#not working url
 #read_images_using_url(url = "https://cdn.pixabay.com/photo/2020/03/25/15/15/honda-4967605_960_720.png")

# show images which are downloaded
def read_images(path):
  import matplotlib.pyplot as plt
  image=cv2.imread(path)
  plt.imshow(image)

#car_image 
read_images(path='/content/car1.jpg')

#man image
read_images(path='/content/man_image.jpg')

#dog image
read_images(path='/content/dog.jpg')

#train data
df=pd.read_csv('car_data_train.csv')

df.head()

#test data
image_1=('/content/car1.jpg')
data = {
    "year": [2010],
    "make": ["TOYOTA"],
    "model":  ["AVALON HYBRID"],
    "color": ["black"],
    "odometer": [143386],
}

# Convert input data into a DataFrame
test = pd.DataFrame(data)

#to preprocess the train data with test data and return x_train,y_train



def preprocessing_test(train,test1,cols=None):
    x=train.drop([cols],axis=1)
    y=train[cols]
    test=test1.copy()
    
    from sklearn.model_selection import train_test_split
    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=123)
    
    
    change_type=x_train.select_dtypes(include=['object']).columns
    change_type_test=test.select_dtypes(include=['object']).columns
    x_train[change_type]=x_train[change_type].astype('category')
    x_test[change_type]=x_test[change_type].astype('category')
    test[change_type_test]=test[change_type_test].astype('category')

    
    cat_cols_x_train=x_train.select_dtypes(include=['category']).columns
    cat_cols_x_test=x_test.select_dtypes(include=['category']).columns
    cat_cols_test=test.select_dtypes(include=['category']).columns

   # print(cat_cols_x_train.shape)
    #print(cat_cols_x_test.shape)
    #print(cat_cols_test.shape)
    #print(x_test)
    #print(test.dtypes)
    
    from sklearn.impute import SimpleImputer
    imputer = SimpleImputer(strategy='mean')
    num_cols = x_train.select_dtypes(['int','float']).columns

    imputer = imputer.fit(x_train[num_cols])
    x_train[num_cols] = imputer.transform(x_train[num_cols])
    x_test[num_cols] = imputer.transform(x_test[num_cols])
    test[num_cols] = imputer.transform(test[num_cols])

    
    
    imputer_cat=SimpleImputer(strategy='most_frequent')
    imputer_cat = imputer_cat.fit(x_train[cat_cols_x_train])
    x_train[cat_cols_x_train] = imputer_cat.transform(x_train[cat_cols_x_train])
    x_test[cat_cols_x_test] = imputer_cat.transform(x_test[cat_cols_x_test])
    test[cat_cols_test] = imputer_cat.transform(test[cat_cols_test])

    #print(x_train.isna().sum())
    
    from sklearn.preprocessing import StandardScaler

    scaler = StandardScaler()
    scaler.fit(x_train[num_cols])
    x_train[num_cols]=scaler.transform(x_train[num_cols])
    x_test[num_cols]=scaler.transform(x_test[num_cols])
    test[num_cols]=scaler.transform(test[num_cols])

    
    change_type=x_train.select_dtypes(include=['object']).columns
    change_type_test=test.select_dtypes(include=['object']).columns
    x_train[change_type]=x_train[change_type].astype('category')
    x_test[change_type]=x_test[change_type].astype('category')
    test[change_type_test]=test[change_type_test].astype('category')

    
    cat_cols_x_train=x_train.select_dtypes(include=['category']).columns
    cat_cols_x_test=x_test.select_dtypes(include=['category']).columns
    cat_cols_test=test.select_dtypes(include=['category']).columns
    
    from sklearn.preprocessing import OneHotEncoder
    ohe=OneHotEncoder(handle_unknown='ignore',drop= 'first')
    ohe=ohe.fit(x_train[cat_cols_x_train])
    
    
    col_ohe_x_train= list(ohe.get_feature_names_out(cat_cols_x_train))
    cat_cols_x_train=ohe.transform(x_train[cat_cols_x_train])
    cat_cols_x_train=pd.DataFrame(cat_cols_x_train.todense(),columns=col_ohe_x_train)
    #print(cat_cols_x_train.shape)
    
    col_ohe_x_test= list(ohe.get_feature_names_out(cat_cols_x_test))
    cat_cols_x_test=ohe.transform(x_test[cat_cols_x_test])
    cat_cols_x_test=pd.DataFrame(cat_cols_x_test.todense(),columns=col_ohe_x_test)
    #print(cat_cols_x_test.shape)


    col_ohe_test= list(ohe.get_feature_names_out(cat_cols_test))
    cat_cols_test=ohe.transform(test[cat_cols_test])
    cat_cols_test=pd.DataFrame(cat_cols_test.todense(),columns=col_ohe_test)
    #print(cat_cols_test.shape)
    
    train_num=x_train.select_dtypes(include=['int','float64'])
    x_test_num=x_test.select_dtypes(include=['int','float'])
    test_num=test.select_dtypes(include=['int','float'])
    
    train_num.reset_index(inplace = True, drop = True)
    x_test_num.reset_index(inplace = True, drop = True)
    test_num.reset_index(inplace = True, drop = True)
    
    x_train = pd.concat([cat_cols_x_train,train_num],axis='columns')
    x_test= pd.concat([cat_cols_x_test,x_test_num],axis='columns')
    test = pd.concat([cat_cols_test,test_num],axis='columns')

    
    return x_train,x_test,y_train,y_test,test

#checking the fumction 
x_train_prepro,x_test_Prepro,y_train_prepro,y_test_prepro,test_prepro=preprocessing_test(df,test,cols='Price')

#test data
test



#function that takes image input data image and test_data 
def get_out(path,test1):
  car_classifier = cv2.CascadeClassifier('/content/haarcascade_car.xml')#haarcascade_car.xml is a pre-trained Haar Cascade Classifier specifically designed for detecting cars in images.
  img = cv2.imread(path)
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  cars = car_classifier.detectMultiScale(gray, 1.4, 2)
  if len(cars) > 0:
    print("Yes, car found in the image!")
    x_train,x_test,y_train,y_test,test5=preprocessing_test(df,test,cols='Price')
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense
    import tensorflow as tf
    from tensorflow import keras

    model23= keras.Sequential()
    model23.add(Dense(10, activation='sigmoid',input_shape=(x_train.shape[1],)))
    model23.add(Dense(5,activation='sigmoid'))
    model23.add(Dense(1, activation='linear'))
    model23.compile(optimizer='adam', loss='mse', metrics=['mae'])
    result23=model23.fit(x_train,y_train,batch_size=10,epochs=10)

    from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error

    ann_testdata_predict=model23.predict(test5)
    #test_ann=pd.read_csv(test_data)
    test1['price']=ann_testdata_predict
    #test['price']
    #print(test1)
    return test1   
  else:
    print("No car found in the image.")



get_out(image_1,test)





image_2=('/content/dog.jpg')
data = {
   # "images": ['https://cdn.pixabay.com/photo/2022/12/02/10/07/car-racing-7630627_960_720.jpg'],
    "year": [2010],
    "make": ["TOYOTA"],
    "model":  ["AVALON HYBRID"],
    "color": ["black"],
    "odometer": [143386],
}

# Convert input data into a DataFrame
test_2 = pd.DataFrame(data)

get_out(image_2,test_2)

image_3=('/content/man_image.jpg')
data = {
    "year": [2010],
    "make": ["TOYOTA"],
    "model":  ["AVALON HYBRID"],
    "color": ["black"],
    "odometer": [143386],
}

# Convert input data into a DataFrame
test_3 = pd.DataFrame(data)

get_out(image_3,test_3)

